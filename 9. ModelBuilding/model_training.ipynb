{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cf7a548c",
      "metadata": {
        "id": "cf7a548c"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f6909dda",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6909dda",
        "outputId": "cf1eb3e7-f105-463a-e417-702217fc7e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n",
            "Best model: random_forest F1= 0.4708\n",
            "Saved model => /mnt/data/best_model.pkl\n",
            "Report => /mnt/data/performance_report.txt\n",
            "Metrics JSON => /mnt/data/metrics.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3197890288.py:94: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  lines.append(f\"Timestamp (UTC): {datetime.utcnow().isoformat()}\")\n"
          ]
        }
      ],
      "source": [
        "import os, json, re\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import joblib\n",
        "\n",
        "# Optional MLflow\n",
        "try:\n",
        "    import mlflow; import mlflow.sklearn\n",
        "    MLFLOW_AVAILABLE = True\n",
        "except Exception:\n",
        "    MLFLOW_AVAILABLE = False\n",
        "\n",
        "DATA_PATH = r\"/cleaned_data.csv\"\n",
        "MODEL_PATH = r\"/mnt/data/best_model.pkl\"\n",
        "REPORT_PATH = r\"/mnt/data/performance_report.txt\"\n",
        "METRICS_PATH = r\"/mnt/data/metrics.json\"\n",
        "EXPERIMENT_NAME = \"bank_churn_lightweight\"\n",
        "\n",
        "def find_target_column(cols):\n",
        "    # Prefer exact 'Exited', else any column that ends with 'Exited' (e.g., 'num__Exited')\n",
        "    if \"Exited\" in cols:\n",
        "        return \"Exited\"\n",
        "    candidates = [c for c in cols if c.lower().endswith(\"exited\")]\n",
        "    if not candidates:\n",
        "        raise ValueError(\"Target column not found. Expecting 'Exited' or a column ending with 'Exited' (e.g., 'num__Exited').\")\n",
        "    # Pick the shortest name if multiple\n",
        "    return sorted(candidates, key=len)[0]\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    tgt = find_target_column(df.columns.tolist())\n",
        "\n",
        "    y = (df[tgt] > 0).astype(int)  # handle standardized targets like num__Exited\n",
        "    X = df.drop(columns=[tgt])\n",
        "\n",
        "    # Models without extra preprocessing (data already cleaned)\n",
        "    log_reg = LogisticRegression(max_iter=1000)\n",
        "    rf = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "\n",
        "    models = {\"logistic_regression\": log_reg, \"random_forest\": rf}\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "    results = {}\n",
        "    best_name, best_f1, best_model = None, -1.0, None\n",
        "\n",
        "    if MLFLOW_AVAILABLE:\n",
        "        mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "\n",
        "    for name, model in models.items():\n",
        "        if MLFLOW_AVAILABLE:\n",
        "            run = mlflow.start_run(run_name=name)\n",
        "        else:\n",
        "            run = None\n",
        "        try:\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            metrics = dict(\n",
        "                accuracy=accuracy_score(y_test, y_pred),\n",
        "                precision=precision_score(y_test, y_pred, zero_division=0),\n",
        "                recall=recall_score(y_test, y_pred, zero_division=0),\n",
        "                f1=f1_score(y_test, y_pred, zero_division=0)\n",
        "            )\n",
        "            cls_rep = classification_report(y_test, y_pred, digits=4)\n",
        "            results[name] = dict(**metrics, classification_report=cls_rep)\n",
        "\n",
        "            if MLFLOW_AVAILABLE:\n",
        "                mlflow.log_param(\"model_type\", name)\n",
        "                for k,v in metrics.items():\n",
        "                    mlflow.log_metric(k, float(v))\n",
        "\n",
        "            if metrics[\"f1\"] > best_f1:\n",
        "                best_f1, best_name, best_model = metrics[\"f1\"], name, model\n",
        "        finally:\n",
        "            if MLFLOW_AVAILABLE and run is not None:\n",
        "                mlflow.end_run()\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    output_dir = os.path.dirname(MODEL_PATH)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save best model\n",
        "    joblib.dump(best_model, MODEL_PATH)\n",
        "\n",
        "    # Report\n",
        "    lines = []\n",
        "    lines.append(f\"Experiment: {EXPERIMENT_NAME}\")\n",
        "    lines.append(f\"Timestamp (UTC): {datetime.utcnow().isoformat()}\")\n",
        "    lines.append(f\"Detected target column: {tgt}\")\n",
        "    lines.append(\"\")\n",
        "    for name, m in results.items():\n",
        "        lines.append(f\"=== {name} ===\")\n",
        "        lines.append(f\"Accuracy:  {m['accuracy']:.4f}\")\n",
        "        lines.append(f\"Precision: {m['precision']:.4f}\")\n",
        "        lines.append(f\"Recall:    {m['recall']:.4f}\")\n",
        "        lines.append(f\"F1:        {m['f1']:.4f}\")\n",
        "        lines.append(\"Classification Report:\")\n",
        "        lines.append(m[\"classification_report\"])\n",
        "        lines.append(\"\")\n",
        "    lines.append(f\"Best model: {best_name} (by F1 = {best_f1:.4f})\")\n",
        "\n",
        "    with open(REPORT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\\\n\".join(lines))\n",
        "\n",
        "    with open(METRICS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"results\": results, \"best_model\": best_name, \"best_f1\": best_f1}, f, indent=2)\n",
        "\n",
        "    if MLFLOW_AVAILABLE:\n",
        "        mlflow.start_run(run_name=\"artifacts_and_best_model\")\n",
        "        try:\n",
        "            mlflow.log_artifact(REPORT_PATH)\n",
        "            mlflow.log_artifact(METRICS_PATH)\n",
        "            mlflow.log_artifact(MODEL_PATH)\n",
        "        finally:\n",
        "            mlflow.end_run()\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    print(\"Best model:\", best_name, \"F1=\", round(best_f1, 4))\n",
        "    print(\"Saved model =>\", MODEL_PATH)\n",
        "    print(\"Report =>\", REPORT_PATH)\n",
        "    print(\"Metrics JSON =>\", METRICS_PATH)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OukF53eX97Tj"
      },
      "id": "OukF53eX97Tj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}